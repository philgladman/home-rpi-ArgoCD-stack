---
# Source: loki-stack/charts/grafana/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
  name: monitoring-grafana
  namespace: default
---
# Source: loki-stack/charts/loki/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
  annotations:
    {}
  name: monitoring-loki
  namespace: default
automountServiceAccountToken: true
---
# Source: loki-stack/charts/promtail/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: monitoring-promtail
  namespace: default
  labels:
    helm.sh/chart: promtail-6.15.5
    app.kubernetes.io/name: promtail
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "2.9.3"
    app.kubernetes.io/managed-by: Helm
---
# Source: loki-stack/charts/grafana/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  admin-user: "YWRtaW4="
  admin-password: "VmFhNGdqR3hGUVZYSW81Ym50dW5KRDUycjJDaWJqYXpNemYwZGhNSA=="
  ldap-toml: ""
---
# Source: loki-stack/charts/loki/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: monitoring-loki
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
data:
  loki.yaml: YXV0aF9lbmFibGVkOiBmYWxzZQpjaHVua19zdG9yZV9jb25maWc6CiAgbWF4X2xvb2tfYmFja19wZXJpb2Q6IDBzCmNvbXBhY3RvcjoKICBzaGFyZWRfc3RvcmU6IGZpbGVzeXN0ZW0KICB3b3JraW5nX2RpcmVjdG9yeTogL2RhdGEvbG9raS9ib2x0ZGItc2hpcHBlci1jb21wYWN0b3IKaW5nZXN0ZXI6CiAgY2h1bmtfYmxvY2tfc2l6ZTogMjYyMTQ0CiAgY2h1bmtfaWRsZV9wZXJpb2Q6IDNtCiAgY2h1bmtfcmV0YWluX3BlcmlvZDogMW0KICBsaWZlY3ljbGVyOgogICAgcmluZzoKICAgICAgcmVwbGljYXRpb25fZmFjdG9yOiAxCiAgbWF4X3RyYW5zZmVyX3JldHJpZXM6IDAKICB3YWw6CiAgICBkaXI6IC9kYXRhL2xva2kvd2FsCmxpbWl0c19jb25maWc6CiAgZW5mb3JjZV9tZXRyaWNfbmFtZTogZmFsc2UKICBtYXhfZW50cmllc19saW1pdF9wZXJfcXVlcnk6IDUwMDAKICByZWplY3Rfb2xkX3NhbXBsZXM6IHRydWUKICByZWplY3Rfb2xkX3NhbXBsZXNfbWF4X2FnZTogMTY4aAptZW1iZXJsaXN0OgogIGpvaW5fbWVtYmVyczoKICAtICdtb25pdG9yaW5nLWxva2ktbWVtYmVybGlzdCcKc2NoZW1hX2NvbmZpZzoKICBjb25maWdzOgogIC0gZnJvbTogIjIwMjAtMTAtMjQiCiAgICBpbmRleDoKICAgICAgcGVyaW9kOiAyNGgKICAgICAgcHJlZml4OiBpbmRleF8KICAgIG9iamVjdF9zdG9yZTogZmlsZXN5c3RlbQogICAgc2NoZW1hOiB2MTEKICAgIHN0b3JlOiBib2x0ZGItc2hpcHBlcgpzZXJ2ZXI6CiAgZ3JwY19saXN0ZW5fcG9ydDogOTA5NQogIGh0dHBfbGlzdGVuX3BvcnQ6IDMxMDAKc3RvcmFnZV9jb25maWc6CiAgYm9sdGRiX3NoaXBwZXI6CiAgICBhY3RpdmVfaW5kZXhfZGlyZWN0b3J5OiAvZGF0YS9sb2tpL2JvbHRkYi1zaGlwcGVyLWFjdGl2ZQogICAgY2FjaGVfbG9jYXRpb246IC9kYXRhL2xva2kvYm9sdGRiLXNoaXBwZXItY2FjaGUKICAgIGNhY2hlX3R0bDogMjRoCiAgICBzaGFyZWRfc3RvcmU6IGZpbGVzeXN0ZW0KICBmaWxlc3lzdGVtOgogICAgZGlyZWN0b3J5OiAvZGF0YS9sb2tpL2NodW5rcwp0YWJsZV9tYW5hZ2VyOgogIHJldGVudGlvbl9kZWxldGVzX2VuYWJsZWQ6IGZhbHNlCiAgcmV0ZW50aW9uX3BlcmlvZDogMHM=
---
# Source: loki-stack/charts/promtail/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: monitoring-promtail
  namespace: default
  labels:
    helm.sh/chart: promtail-6.15.5
    app.kubernetes.io/name: promtail
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "2.9.3"
    app.kubernetes.io/managed-by: Helm
stringData:
  promtail.yaml: |
    server:
      log_level: info
      log_format: logfmt
      http_listen_port: 3101
      
    
    clients:
      - url: http://monitoring:3100/loki/api/v1/push
    
    positions:
      filename: /run/promtail/positions.yaml
    
    scrape_configs:
      # See also https://github.com/grafana/loki/blob/master/production/ksonnet/promtail/scrape_config.libsonnet for reference
      - job_name: kubernetes-pods
        pipeline_stages:
          - cri: {}
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_controller_name
            regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
            action: replace
            target_label: __tmp_controller_name
          - source_labels:
              - __meta_kubernetes_pod_label_app_kubernetes_io_name
              - __meta_kubernetes_pod_label_app
              - __tmp_controller_name
              - __meta_kubernetes_pod_name
            regex: ^;*([^;]+)(;.*)?$
            action: replace
            target_label: app
          - source_labels:
              - __meta_kubernetes_pod_label_app_kubernetes_io_instance
              - __meta_kubernetes_pod_label_instance
            regex: ^;*([^;]+)(;.*)?$
            action: replace
            target_label: instance
          - source_labels:
              - __meta_kubernetes_pod_label_app_kubernetes_io_component
              - __meta_kubernetes_pod_label_component
            regex: ^;*([^;]+)(;.*)?$
            action: replace
            target_label: component
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_node_name
            target_label: node_name
          - action: replace
            source_labels:
            - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            replacement: $1
            separator: /
            source_labels:
            - namespace
            - app
            target_label: job
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_name
            target_label: pod
          - action: replace
            source_labels:
            - __meta_kubernetes_pod_container_name
            target_label: container
          - action: replace
            replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
            - __meta_kubernetes_pod_uid
            - __meta_kubernetes_pod_container_name
            target_label: __path__
          - action: replace
            regex: true/(.*)
            replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
            - __meta_kubernetes_pod_annotationpresent_kubernetes_io_config_hash
            - __meta_kubernetes_pod_annotation_kubernetes_io_config_hash
            - __meta_kubernetes_pod_container_name
            target_label: __path__
      
      
    
    limits_config:
      
    
    tracing:
      enabled: false
---
# Source: loki-stack/charts/grafana/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
data:
  grafana.ini: |
    [analytics]
    check_for_updates = true
    [grafana_net]
    url = https://grafana.net
    [log]
    mode = console
    [paths]
    data = /var/lib/grafana/
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning
    [server]
    domain = ''

  datasources.yaml: |
    apiVersion: 1
    datasources:
    - access: proxy
      jsonData:
        maxLines: 1000
      name: loki
      type: loki
      url: http://monitoring:3100
---
# Source: loki-stack/charts/grafana/templates/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
  finalizers:
    - kubernetes.io/pvc-protection
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "10Gi"
---
# Source: loki-stack/charts/grafana/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
  name: monitoring-grafana-clusterrole
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["configmaps", "secrets"]
  verbs: ["get", "watch", "list"]
---
# Source: loki-stack/charts/promtail/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: monitoring-promtail
  labels:
    helm.sh/chart: promtail-6.15.5
    app.kubernetes.io/name: promtail
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "2.9.3"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs:
      - get
      - watch
      - list
---
# Source: loki-stack/charts/grafana/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: monitoring-grafana-clusterrolebinding
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: monitoring-grafana
    namespace: default
roleRef:
  kind: ClusterRole
  name: monitoring-grafana-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: loki-stack/charts/promtail/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: monitoring-promtail
  labels:
    helm.sh/chart: promtail-6.15.5
    app.kubernetes.io/name: promtail
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "2.9.3"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: monitoring-promtail
    namespace: default
roleRef:
  kind: ClusterRole
  name: monitoring-promtail
  apiGroup: rbac.authorization.k8s.io
---
# Source: loki-stack/charts/grafana/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:      ['extensions']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [monitoring-grafana]
---
# Source: loki-stack/charts/loki/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: monitoring-loki
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
rules:
- apiGroups:      ['extensions']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [monitoring-loki]
---
# Source: loki-stack/charts/grafana/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: monitoring-grafana
subjects:
- kind: ServiceAccount
  name: monitoring-grafana
  namespace: default
---
# Source: loki-stack/charts/loki/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: monitoring-loki
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: monitoring-loki
subjects:
- kind: ServiceAccount
  name: monitoring-loki
---
# Source: loki-stack/charts/grafana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: service
      port: 80
      protocol: TCP
      targetPort: 3000
  selector:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
---
# Source: loki-stack/charts/loki/templates/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: monitoring-loki-headless
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
    variant: headless
spec:
  clusterIP: None
  ports:
    - port: 3100
      protocol: TCP
      name: http-metrics
      targetPort: http-metrics
  selector:
    app: loki
    release: monitoring
---
# Source: loki-stack/charts/loki/templates/service-memberlist.yaml
apiVersion: v1
kind: Service
metadata:
  name: monitoring-loki-memberlist
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 7946
      targetPort: memberlist-port
      protocol: TCP
  selector:
    app: loki
    release: monitoring
---
# Source: loki-stack/charts/loki/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: monitoring-loki
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - port: 3100
      protocol: TCP
      name: http-metrics
      targetPort: http-metrics
  selector:
    app: loki
    release: monitoring
---
# Source: loki-stack/charts/promtail/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: monitoring-promtail
  namespace: default
  labels:
    helm.sh/chart: promtail-6.15.5
    app.kubernetes.io/name: promtail
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "2.9.3"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: promtail
      app.kubernetes.io/instance: monitoring
  updateStrategy:
    {}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: promtail
        app.kubernetes.io/instance: monitoring
      annotations:
        checksum/config: 94b81ba71edc4f292c4b55aed85d18473f74b0a51c5e5cc5ea108759507f713f
    spec:
      serviceAccountName: monitoring-promtail
      enableServiceLinks: true
      securityContext:
        runAsGroup: 0
        runAsUser: 0
      containers:
        - name: promtail
          image: "docker.io/grafana/promtail:2.9.3"
          imagePullPolicy: IfNotPresent
          args:
            - "-config.file=/etc/promtail/promtail.yaml"
          volumeMounts:
            - name: config
              mountPath: /etc/promtail
            - mountPath: /run/promtail
              name: run
            - mountPath: /var/lib/docker/containers
              name: containers
              readOnly: true
            - mountPath: /var/log/pods
              name: pods
              readOnly: true
          env:
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          ports:
            - name: http-metrics
              containerPort: 3101
              protocol: TCP
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: '/ready'
              port: http-metrics
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
      volumes:
        - name: config
          secret:
            secretName: monitoring-promtail
        - hostPath:
            path: /run/promtail
          name: run
        - hostPath:
            path: /var/lib/docker/containers
          name: containers
        - hostPath:
            path: /var/log/pods
          name: pods
---
# Source: loki-stack/charts/grafana/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: monitoring-grafana
  namespace: default
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
      app.kubernetes.io/instance: monitoring
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: grafana
        app.kubernetes.io/instance: monitoring
      annotations:
        checksum/config: a976b7f1b55c65fc584662567283800d54bc81f93248714972bd9b15de71872c
        checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/sc-dashboard-provider-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/secret: c3a268c6042ffa407f46408698e191b23465f8a54d40cde01ea3580487e02a60
    spec:      
      serviceAccountName: monitoring-grafana
      automountServiceAccountToken: true
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsUser: 472
      initContainers:
        - name: init-chown-data
          image: "busybox:1.31.1"
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: false
            runAsUser: 0
          command: ["chown", "-R", "472:472", "/var/lib/grafana"]
          volumeMounts:
            - name: storage
              mountPath: "/var/lib/grafana"
      enableServiceLinks: true
      containers:
        - name: grafana-sc-datasources
          image: "quay.io/kiwigrid/k8s-sidecar:1.19.2"
          imagePullPolicy: IfNotPresent
          env:
            - name: METHOD
              value: WATCH
            - name: LABEL
              value: ""
            - name: FOLDER
              value: "/etc/grafana/provisioning/datasources"
            - name: RESOURCE
              value: "both"
            - name: REQ_USERNAME
              valueFrom:
                secretKeyRef:
                  name: monitoring-grafana
                  key: admin-user
            - name: REQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: monitoring-grafana
                  key: admin-password
            - name: REQ_URL
              value: http://localhost:3000/api/admin/provisioning/datasources/reload
            - name: REQ_METHOD
              value: POST
          volumeMounts:
            - name: sc-datasources-volume
              mountPath: "/etc/grafana/provisioning/datasources"
        - name: grafana
          image: "grafana/grafana:8.3.5"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/etc/grafana/grafana.ini"
              subPath: grafana.ini
            - name: storage
              mountPath: "/var/lib/grafana"
            - name: config
              mountPath: "/etc/grafana/provisioning/datasources/datasources.yaml"
              subPath: "datasources.yaml"
            - name: sc-datasources-volume
              mountPath: "/etc/grafana/provisioning/datasources"
          ports:
            - name: grafana
              containerPort: 3000
              protocol: TCP
          env:
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  name: monitoring-grafana
                  key: admin-user
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: monitoring-grafana
                  key: admin-password
            - name: GF_PATHS_DATA
              value: /var/lib/grafana/
            - name: GF_PATHS_LOGS
              value: /var/log/grafana
            - name: GF_PATHS_PLUGINS
              value: /var/lib/grafana/plugins
            - name: GF_PATHS_PROVISIONING
              value: /etc/grafana/provisioning
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 60
            timeoutSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
      volumes:
        - name: config
          configMap:
            name: monitoring-grafana
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - name: sc-datasources-volume
          emptyDir: {}
---
# Source: loki-stack/charts/loki/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: monitoring-loki
  namespace: default
  labels:
    app: loki
    chart: loki-2.16.0
    release: monitoring
    heritage: Helm
  annotations:
    {}
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  selector:
    matchLabels:
      app: loki
      release: monitoring
  serviceName: monitoring-loki-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: loki
        name: monitoring-loki
        release: monitoring
      annotations:
        checksum/config: c52cd27dc94f1045479197adb0b03c7d6ff63ff93574d4c685360d20e5fc1aac
        prometheus.io/port: http-metrics
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: monitoring-loki
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      initContainers:
        []
      containers:
        - name: loki
          image: "grafana/loki:2.6.1"
          imagePullPolicy: IfNotPresent
          args:
            - "-config.file=/etc/loki/loki.yaml"
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: config
              mountPath: /etc/loki
            - name: storage
              mountPath: "/data"
              subPath: 
          ports:
            - name: http-metrics
              containerPort: 3100
              protocol: TCP
            - name: grpc
              containerPort: 9095
              protocol: TCP
            - name: memberlist-port
              containerPort: 7946
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 45
          readinessProbe:
            httpGet:
              path: /ready
              port: http-metrics
            initialDelaySeconds: 45
          resources:
            {}
          securityContext:
            readOnlyRootFilesystem: true
          env:
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      terminationGracePeriodSeconds: 4800
      volumes:
        - name: tmp
          emptyDir: {}
        - name: config
          secret:
            secretName: monitoring-loki
        - name: storage
          emptyDir: {}
---
# Source: loki-stack/charts/grafana/templates/tests/test-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
  name: monitoring-grafana-test
  namespace: default
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
---
# Source: loki-stack/charts/grafana/templates/tests/test-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: monitoring-grafana-test
  namespace: default
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
data:
  run.sh: |-
    @test "Test Health" {
      url="http://monitoring-grafana/api/health"

      code=$(wget --server-response --spider --timeout 90 --tries 10 ${url} 2>&1 | awk '/^  HTTP/{print $2}')
      [ "$code" == "200" ]
    }
---
# Source: loki-stack/charts/grafana/templates/tests/test-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: monitoring-grafana-test
  namespace: default
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:      ['policy']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [monitoring-grafana-test]
---
# Source: loki-stack/charts/grafana/templates/tests/test-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: monitoring-grafana-test
  namespace: default
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: monitoring-grafana-test
subjects:
- kind: ServiceAccount
  name: monitoring-grafana-test
  namespace: default
---
# Source: loki-stack/charts/grafana/templates/tests/test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: monitoring-grafana-test
  labels:
    helm.sh/chart: grafana-6.43.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "8.3.5"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  namespace: default
spec:
  serviceAccountName: monitoring-grafana-test
  containers:
    - name: monitoring-test
      image: "bats/bats:v1.4.1"
      imagePullPolicy: "IfNotPresent"
      command: ["/opt/bats/bin/bats", "-t", "/tests/run.sh"]
      volumeMounts:
        - mountPath: /tests
          name: tests
          readOnly: true
  volumes:
  - name: tests
    configMap:
      name: monitoring-grafana-test
  restartPolicy: Never
